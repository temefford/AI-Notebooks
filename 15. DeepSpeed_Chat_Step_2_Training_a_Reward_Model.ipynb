{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ2g_OXwxcwg"
      },
      "source": [
        "This notebook trains a reward model with DeepSpeed Chat using OPT-350 as a base model.\n",
        "This is the second step for training an instruct LLMs with DeepSpeed Chat.\n",
        "The details of the steps are explained in this article: [Train Instruct LLMs On Your GPU with DeepSpeed Chat — Step #2: Training a Reward Model](https://kaitchup.substack.com/p/train-instruct-llms-on-your-gpu-with-1e1)\n",
        "\n",
        "You can find more details on supervised fine-tuning using DeepSpeed Chat in this article: [Train Instruct LLMs On Your GPU with DeepSpeed Chat — Step #1: Supervised Fine-tuning](https://kaitchup.substack.com/p/train-instruct-llms-on-your-gpu-with)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84d1tpfS9SxK",
        "outputId": "350a9b8e-5a68-495d-e6df-fff70626dbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeedExamples'...\n",
            "remote: Enumerating objects: 8652, done.\u001b[K\n",
            "remote: Counting objects: 100% (1761/1761), done.\u001b[K\n",
            "remote: Compressing objects: 100% (307/307), done.\u001b[K\n",
            "remote: Total 8652 (delta 1562), reused 1503 (delta 1422), pack-reused 6891\u001b[K\n",
            "Receiving objects: 100% (8652/8652), 22.37 MiB | 21.90 MiB/s, done.\n",
            "Resolving deltas: 100% (4891/4891), done.\n",
            "/content/DeepSpeedExamples/applications/DeepSpeed-Chat\n",
            "Collecting datasets>=2.8.0 (from -r requirements.txt (line 1))\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.97 (from -r requirements.txt (line 2))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.20.3)\n",
            "Collecting accelerate>=0.15.0 (from -r requirements.txt (line 4))\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Requirement already satisfied: deepspeed>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.10.3)\n",
            "Collecting transformers>=4.31.0 (from -r requirements.txt (line 7))\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (4.66.1)\n",
            "Collecting xxhash (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12.0->-r requirements.txt (line 5)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12.0->-r requirements.txt (line 5)) (16.0.6)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (1.11.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (9.0.0)\n",
            "Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (1.10.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->-r requirements.txt (line 7)) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.31.0->-r requirements.txt (line 7))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.31.0->-r requirements.txt (line 7))\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.41.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 8)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.8.0->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.8.0->-r requirements.txt (line 1)) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 8)) (3.2.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets, accelerate\n",
            "Successfully installed accelerate-0.22.0 datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.1 multiprocess-0.70.15 safetensors-0.3.3 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.33.1 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install deepspeed>=0.9.0\n",
        "\n",
        "!git clone https://github.com/microsoft/DeepSpeedExamples.git\n",
        "%cd DeepSpeedExamples/applications/DeepSpeed-Chat/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a reward model using opt-350 as a base model. It requires at least 41 GB of CPU RAM and 10 GB of VRAM.\n",
        "The reward model is saved in a directory named rm_ds."
      ],
      "metadata": {
        "id": "EDGDmGhYah4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIOqUsWdJKtc",
        "outputId": "a2b89e3f-31d9-4384-f2a7-9c765af0bc99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning\n",
            "[2023-09-14 11:17:02,998] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-09-14 11:17:08.240743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-09-14 11:17:09,231] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2023-09-14 11:17:09,231] [INFO] [runner.py:570:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None main.py --model_name_or_path facebook/opt-350m --data_path Dahoas/rm-static Dahoas/full-hh-rlhf Dahoas/synthetic-instruct-gptj-pairwise yitingxie/rlhf-reward-datasets --data_split 2,4,4 --gradient_checkpointing --num_train_epochs 1 --per_device_eval_batch_size 4 --per_device_train_batch_size 4 --seed 1234 --num_padding_at_beginning 1 --weight_decay 0.1 --disable_dropout --gradient_accumulation_steps 16 --zero_stage 0 --deepspeed --output_dir ./rm_ds/\n",
            "[2023-09-14 11:17:11,289] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-09-14 11:17:15.582500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2023-09-14 11:17:16,406] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "2023-09-14 11:17:19.877511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-09-14 11:17:21,542] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "[2023-09-14 11:17:26,250] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2023-09-14 11:17:26,250] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50272. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "> Creating model from_config took 6.13692045211792 seconds\n",
            "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.09835290908813477 seconds\n",
            "[2023-09-14 11:19:21,105] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown\n",
            "[2023-09-14 11:19:21,105] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized\n",
            "[2023-09-14 11:19:21,426] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2023-09-14 11:19:21,427] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
            "[2023-09-14 11:19:21,427] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2023-09-14 11:19:21,449] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2023-09-14 11:19:21,449] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n",
            "[2023-09-14 11:19:21,474] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
            "[2023-09-14 11:19:21,474] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2023-09-14 11:19:21,474] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x78d9880d4220>\n",
            "[2023-09-14 11:19:21,474] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:19:21,475] [INFO] [config.py:967:print] DeepSpeedEngine configuration:\n",
            "[2023-09-14 11:19:21,475] [INFO] [config.py:971:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-09-14 11:19:21,475] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   amp_enabled .................. False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   amp_params ................... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   bfloat16_enabled ............. False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x78d987ad1660>\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   communication_data_type ...... None\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   dataloader_drop_last ......... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   disable_allgather ............ False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   dump_state ................... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-09-14 11:19:21,476] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   elasticity_enabled ........... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   fp16_auto_cast ............... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   fp16_enabled ................. True\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   global_rank .................. 0\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   grad_accum_dtype ............. None\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 16\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 65536\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   load_universal_checkpoint .... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   loss_scale ................... 0\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   memory_breakdown ............. False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   mics_shard_size .............. -1\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step2_tensorboard/ds_tensorboard_logs/', job_name='step2_model_tensorboard') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   optimizer_name ............... None\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   optimizer_params ............. None\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   pld_enabled .................. False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   pld_params ................... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   prescale_gradients ........... False\n",
            "[2023-09-14 11:19:21,477] [INFO] [config.py:971:print]   scheduler_name ............... None\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   scheduler_params ............. None\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   sparse_attention ............. None\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   steps_per_print .............. 10\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   train_batch_size ............. 64\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  4\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   use_node_local_storage ....... False\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   weight_quantization_config ... None\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   world_size ................... 1\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   zero_enabled ................. False\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:971:print]   zero_optimization_stage ...... 0\n",
            "[2023-09-14 11:19:21,478] [INFO] [config.py:957:print_user_config]   json = {\n",
            "    \"train_batch_size\": 64, \n",
            "    \"train_micro_batch_size_per_gpu\": 4, \n",
            "    \"steps_per_print\": 10, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 0, \n",
            "        \"offload_param\": {\n",
            "            \"device\": \"none\"\n",
            "        }, \n",
            "        \"offload_optimizer\": {\n",
            "            \"device\": \"none\"\n",
            "        }, \n",
            "        \"stage3_param_persistence_threshold\": 1.000000e+04, \n",
            "        \"stage3_max_live_parameters\": 3.000000e+07, \n",
            "        \"stage3_prefetch_bucket_size\": 3.000000e+07, \n",
            "        \"memory_efficient_linear\": false\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": true, \n",
            "        \"loss_scale_window\": 100\n",
            "    }, \n",
            "    \"gradient_clipping\": 1.0, \n",
            "    \"prescale_gradients\": false, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"hybrid_engine\": {\n",
            "        \"enabled\": false, \n",
            "        \"max_out_tokens\": 512, \n",
            "        \"inference_tp_size\": 1, \n",
            "        \"release_inference_cache\": false, \n",
            "        \"pin_parameters\": true, \n",
            "        \"tp_gather_partition_size\": 8\n",
            "    }, \n",
            "    \"tensorboard\": {\n",
            "        \"enabled\": false, \n",
            "        \"output_path\": \"step2_tensorboard/ds_tensorboard_logs/\", \n",
            "        \"job_name\": \"step2_model_tensorboard\"\n",
            "    }\n",
            "}\n",
            "***** Running training *****\n",
            "***** Evaluating reward, Epoch 0/1 *****\n",
            "chosen_last_scores (higher is better) : 2.575861692428589, acc (higher is better) : 0.492499977350235\n",
            "Beginning of Epoch 1/1, Total Micro Batches 29440\n",
            "[2023-09-14 11:19:34,191] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 0\n",
            "[2023-09-14 11:19:34,191] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0\n",
            "[2023-09-14 11:19:34,191] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
            "[2023-09-14 11:19:38,984] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1\n",
            "[2023-09-14 11:19:38,984] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n",
            "[2023-09-14 11:19:38,984] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "[2023-09-14 11:19:43,782] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 2\n",
            "[2023-09-14 11:19:43,782] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0\n",
            "[2023-09-14 11:19:43,782] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
            "[2023-09-14 11:19:48,573] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 3\n",
            "[2023-09-14 11:19:48,573] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0\n",
            "[2023-09-14 11:19:48,573] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
            "[2023-09-14 11:20:17,625] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=4, lr=[4.9998688184328044e-05, 4.9998688184328044e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:20:17,640] [INFO] [timer.py:260:stop] epoch=0/micro_step=160/global_step=10, RunningAvgSamplesPerSec=13.274203479913798, CurrSamplesPerSec=13.240753820259396, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:21:06,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=4, lr=[4.999067203154777e-05, 4.999067203154777e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:21:06,140] [INFO] [timer.py:260:stop] epoch=0/micro_step=320/global_step=20, RunningAvgSamplesPerSec=13.24694157849415, CurrSamplesPerSec=13.224023398897566, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:21:54,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=4, lr=[4.99753708464281e-05, 4.99753708464281e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:21:54,650] [INFO] [timer.py:260:stop] epoch=0/micro_step=480/global_step=30, RunningAvgSamplesPerSec=13.238343354633743, CurrSamplesPerSec=13.225157686957425, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:22:43,164] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=4, lr=[4.995278908941845e-05, 4.995278908941845e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:22:43,178] [INFO] [timer.py:260:stop] epoch=0/micro_step=640/global_step=40, RunningAvgSamplesPerSec=13.23294573356099, CurrSamplesPerSec=13.208756504723967, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:23:31,687] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=4, lr=[4.99229333433282e-05, 4.99229333433282e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:23:31,701] [INFO] [timer.py:260:stop] epoch=0/micro_step=800/global_step=50, RunningAvgSamplesPerSec=13.230016323253745, CurrSamplesPerSec=13.212472698732114, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:24:20,176] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=4, lr=[4.988581231140772e-05, 4.988581231140772e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:24:20,191] [INFO] [timer.py:260:stop] epoch=0/micro_step=960/global_step=60, RunningAvgSamplesPerSec=13.229611326896348, CurrSamplesPerSec=13.248724583848068, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:25:08,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=4, lr=[4.984143681481132e-05, 4.984143681481132e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:25:08,705] [INFO] [timer.py:260:stop] epoch=0/micro_step=1120/global_step=70, RunningAvgSamplesPerSec=13.22841094810128, CurrSamplesPerSec=13.220362559460996, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:25:57,195] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=4, lr=[4.978981978944271e-05, 4.978981978944271e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:25:57,210] [INFO] [timer.py:260:stop] epoch=0/micro_step=1280/global_step=80, RunningAvgSamplesPerSec=13.227862126452422, CurrSamplesPerSec=13.235161000442067, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:26:45,712] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=4, lr=[4.973097628218415e-05, 4.973097628218415e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:26:45,726] [INFO] [timer.py:260:stop] epoch=0/micro_step=1440/global_step=90, RunningAvgSamplesPerSec=13.22705251254864, CurrSamplesPerSec=13.231034210816864, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:27:34,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=4, lr=[4.966492344651005e-05, 4.966492344651005e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:27:34,188] [INFO] [timer.py:260:stop] epoch=0/micro_step=1600/global_step=100, RunningAvgSamplesPerSec=13.2278618012158, CurrSamplesPerSec=13.221026062371557, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:27:58,420] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 11:27:58,420] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 4096.0 to 8192.0\n",
            "[2023-09-14 11:28:22,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=4, lr=[4.95916805374866e-05, 4.95916805374866e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:28:22,704] [INFO] [timer.py:260:stop] epoch=0/micro_step=1760/global_step=110, RunningAvgSamplesPerSec=13.227220176914438, CurrSamplesPerSec=13.227005800931572, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:29:11,181] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=4, lr=[4.95112689061587e-05, 4.95112689061587e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:29:11,195] [INFO] [timer.py:260:stop] epoch=0/micro_step=1920/global_step=120, RunningAvgSamplesPerSec=13.22723523310393, CurrSamplesPerSec=13.228101488911003, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:29:59,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=4, lr=[4.9423711993325955e-05, 4.9423711993325955e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:29:59,652] [INFO] [timer.py:260:stop] epoch=0/micro_step=2080/global_step=130, RunningAvgSamplesPerSec=13.227955514345618, CurrSamplesPerSec=13.240730961490446, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:30:48,175] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=4, lr=[4.9329035322709386e-05, 4.9329035322709386e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:30:48,189] [INFO] [timer.py:260:stop] epoch=0/micro_step=2240/global_step=140, RunningAvgSamplesPerSec=13.22705048396335, CurrSamplesPerSec=13.213398821918231, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:31:36,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=4, lr=[4.922726649351108e-05, 4.922726649351108e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:31:36,692] [INFO] [timer.py:260:stop] epoch=0/micro_step=2400/global_step=150, RunningAvgSamplesPerSec=13.22686860389055, CurrSamplesPerSec=13.22871948223599, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:32:25,171] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=4, lr=[4.9118435172368673e-05, 4.9118435172368673e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:32:25,185] [INFO] [timer.py:260:stop] epoch=0/micro_step=2560/global_step=160, RunningAvgSamplesPerSec=13.226837902349066, CurrSamplesPerSec=13.23442495686808, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:33:13,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=4, lr=[4.900257308470728e-05, 4.900257308470728e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:33:13,686] [INFO] [timer.py:260:stop] epoch=0/micro_step=2720/global_step=170, RunningAvgSamplesPerSec=13.226721495202696, CurrSamplesPerSec=13.220772113253364, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:34:02,150] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=4, lr=[4.88797140054912e-05, 4.88797140054912e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:34:02,165] [INFO] [timer.py:260:stop] epoch=0/micro_step=2880/global_step=180, RunningAvgSamplesPerSec=13.226952104736645, CurrSamplesPerSec=13.241911230237491, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:34:50,634] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=4, lr=[4.874989374937817e-05, 4.874989374937817e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:34:50,649] [INFO] [timer.py:260:stop] epoch=0/micro_step=3040/global_step=190, RunningAvgSamplesPerSec=13.227074859403077, CurrSamplesPerSec=13.22008454614707, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:35:39,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=4, lr=[4.861315016027902e-05, 4.861315016027902e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:35:39,133] [INFO] [timer.py:260:stop] epoch=0/micro_step=3200/global_step=200, RunningAvgSamplesPerSec=13.227176555905608, CurrSamplesPerSec=13.232103171534073, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:36:03,347] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 11:36:03,347] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 8192.0 to 16384.0\n",
            "[2023-09-14 11:36:27,606] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=4, lr=[4.84695231003258e-05, 4.84695231003258e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:36:27,620] [INFO] [timer.py:260:stop] epoch=0/micro_step=3360/global_step=210, RunningAvgSamplesPerSec=13.227227911517202, CurrSamplesPerSec=13.237600708857803, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:37:16,065] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=4, lr=[4.831905443825159e-05, 4.831905443825159e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:37:16,079] [INFO] [timer.py:260:stop] epoch=0/micro_step=3520/global_step=220, RunningAvgSamplesPerSec=13.22762011288432, CurrSamplesPerSec=13.221513151057508, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:38:04,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=4, lr=[4.8161788037185327e-05, 4.8161788037185327e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:38:04,539] [INFO] [timer.py:260:stop] epoch=0/micro_step=3680/global_step=230, RunningAvgSamplesPerSec=13.227946853793929, CurrSamplesPerSec=13.25524320306691, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:38:52,969] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=4, lr=[4.7997769741865226e-05, 4.7997769741865226e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:38:52,983] [INFO] [timer.py:260:stop] epoch=0/micro_step=3840/global_step=240, RunningAvgSamplesPerSec=13.228427545340558, CurrSamplesPerSec=13.243535995162702, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:39:41,428] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=4, lr=[4.782704736527466e-05, 4.782704736527466e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:39:41,442] [INFO] [timer.py:260:stop] epoch=0/micro_step=4000/global_step=250, RunningAvgSamplesPerSec=13.228743167030636, CurrSamplesPerSec=13.235788137616067, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:40:29,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=4, lr=[4.76496706747041e-05, 4.76496706747041e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:40:29,916] [INFO] [timer.py:260:stop] epoch=0/micro_step=4160/global_step=260, RunningAvgSamplesPerSec=13.228858977358843, CurrSamplesPerSec=13.217940915828152, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:41:18,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=4, lr=[4.74656913772435e-05, 4.74656913772435e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:41:18,389] [INFO] [timer.py:260:stop] epoch=0/micro_step=4320/global_step=270, RunningAvgSamplesPerSec=13.228966523990236, CurrSamplesPerSec=13.224219491077664, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:42:06,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=4, lr=[4.72751631047092e-05, 4.72751631047092e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:42:06,874] [INFO] [timer.py:260:stop] epoch=0/micro_step=4480/global_step=280, RunningAvgSamplesPerSec=13.22896427884243, CurrSamplesPerSec=13.228497832419436, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:42:55,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=4, lr=[4.707814139800961e-05, 4.707814139800961e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:42:55,355] [INFO] [timer.py:260:stop] epoch=0/micro_step=4640/global_step=290, RunningAvgSamplesPerSec=13.229009512460253, CurrSamplesPerSec=13.237165959807923, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:43:43,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=4, lr=[4.687468369095457e-05, 4.687468369095457e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:43:43,841] [INFO] [timer.py:260:stop] epoch=0/micro_step=4800/global_step=300, RunningAvgSamplesPerSec=13.228996110838892, CurrSamplesPerSec=13.216306807842557, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:44:08,052] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 11:44:08,052] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n",
            "[2023-09-14 11:44:32,306] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=4, lr=[4.666484929351275e-05, 4.666484929351275e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:44:32,320] [INFO] [timer.py:260:stop] epoch=0/micro_step=4960/global_step=310, RunningAvgSamplesPerSec=13.229047777633927, CurrSamplesPerSec=13.214392077216598, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:45:20,806] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=4, lr=[4.644869937452224e-05, 4.644869937452224e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:45:20,820] [INFO] [timer.py:260:stop] epoch=0/micro_step=5120/global_step=320, RunningAvgSamplesPerSec=13.228934601592396, CurrSamplesPerSec=13.234291851346274, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:46:09,320] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=4, lr=[4.6226296943859225e-05, 4.6226296943859225e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:46:09,334] [INFO] [timer.py:260:stop] epoch=0/micro_step=5280/global_step=330, RunningAvgSamplesPerSec=13.228725838479988, CurrSamplesPerSec=13.210159908926896, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:46:57,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=4, lr=[4.599770683406991e-05, 4.599770683406991e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:46:57,856] [INFO] [timer.py:260:stop] epoch=0/micro_step=5440/global_step=340, RunningAvgSamplesPerSec=13.228460913363936, CurrSamplesPerSec=13.23155203842992, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:47:46,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=4, lr=[4.5762995681471266e-05, 4.5762995681471266e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:47:46,342] [INFO] [timer.py:260:stop] epoch=0/micro_step=5600/global_step=350, RunningAvgSamplesPerSec=13.22846553346091, CurrSamplesPerSec=13.23026145783251, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:48:34,804] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=4, lr=[4.552223190672579e-05, 4.552223190672579e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:48:34,818] [INFO] [timer.py:260:stop] epoch=0/micro_step=5760/global_step=360, RunningAvgSamplesPerSec=13.228542362094446, CurrSamplesPerSec=13.246444189354127, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:49:23,294] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=4, lr=[4.527548569489626e-05, 4.527548569489626e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:49:23,309] [INFO] [timer.py:260:stop] epoch=0/micro_step=5920/global_step=370, RunningAvgSamplesPerSec=13.228521897858887, CurrSamplesPerSec=13.240341068357353, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:50:11,790] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=4, lr=[4.5022828974986044e-05, 4.5022828974986044e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:50:11,804] [INFO] [timer.py:260:stop] epoch=0/micro_step=6080/global_step=380, RunningAvgSamplesPerSec=13.22847887042592, CurrSamplesPerSec=13.216866432943503, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:51:00,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=4, lr=[4.476433539897109e-05, 4.476433539897109e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:51:00,335] [INFO] [timer.py:260:stop] epoch=0/micro_step=6240/global_step=390, RunningAvgSamplesPerSec=13.228190369444118, CurrSamplesPerSec=13.22772863479192, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:51:48,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=4, lr=[4.4500080320329615e-05, 4.4500080320329615e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:51:48,860] [INFO] [timer.py:260:stop] epoch=0/micro_step=6400/global_step=400, RunningAvgSamplesPerSec=13.227966335544508, CurrSamplesPerSec=13.223926332162927, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:52:13,090] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 11:52:13,090] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n",
            "[2023-09-14 11:52:37,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=4, lr=[4.423014077207585e-05, 4.423014077207585e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:52:37,392] [INFO] [timer.py:260:stop] epoch=0/micro_step=6560/global_step=410, RunningAvgSamplesPerSec=13.227706658118343, CurrSamplesPerSec=13.222512837172026, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:53:25,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=4, lr=[4.395459544430407e-05, 4.395459544430407e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:53:25,904] [INFO] [timer.py:260:stop] epoch=0/micro_step=6720/global_step=420, RunningAvgSamplesPerSec=13.227568821208594, CurrSamplesPerSec=13.228175801509744, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:54:14,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=4, lr=[4.367352466124972e-05, 4.367352466124972e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:54:14,418] [INFO] [timer.py:260:stop] epoch=0/micro_step=6880/global_step=430, RunningAvgSamplesPerSec=13.227435711656467, CurrSamplesPerSec=13.206364449777896, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:55:02,894] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=4, lr=[4.3387010357874026e-05, 4.3387010357874026e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:55:02,908] [INFO] [timer.py:260:stop] epoch=0/micro_step=7040/global_step=440, RunningAvgSamplesPerSec=13.227442964739954, CurrSamplesPerSec=13.259108073290658, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:55:51,320] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=4, lr=[4.309513605597918e-05, 4.309513605597918e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:55:51,334] [INFO] [timer.py:260:stop] epoch=0/micro_step=7200/global_step=450, RunningAvgSamplesPerSec=13.227825089515498, CurrSamplesPerSec=13.245608851398174, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:56:39,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=4, lr=[4.279798683986084e-05, 4.279798683986084e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:56:39,816] [INFO] [timer.py:260:stop] epoch=0/micro_step=7360/global_step=460, RunningAvgSamplesPerSec=13.227869969784264, CurrSamplesPerSec=13.222985054187866, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:57:28,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=4, lr=[4.2495649331505284e-05, 4.2495649331505284e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:57:28,276] [INFO] [timer.py:260:stop] epoch=0/micro_step=7520/global_step=470, RunningAvgSamplesPerSec=13.228044381655815, CurrSamplesPerSec=13.228324429212089, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:58:16,768] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=4, lr=[4.2188211665338126e-05, 4.2188211665338126e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:58:16,782] [INFO] [timer.py:260:stop] epoch=0/micro_step=7680/global_step=480, RunningAvgSamplesPerSec=13.227954692207234, CurrSamplesPerSec=13.215995780892765, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:59:05,213] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=4, lr=[4.187576346253234e-05, 4.187576346253234e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:59:05,228] [INFO] [timer.py:260:stop] epoch=0/micro_step=7840/global_step=490, RunningAvgSamplesPerSec=13.22818282245849, CurrSamplesPerSec=13.249228756367266, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 11:59:53,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=4, lr=[4.1558395804882695e-05, 4.1558395804882695e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 11:59:53,690] [INFO] [timer.py:260:stop] epoch=0/micro_step=8000/global_step=500, RunningAvgSamplesPerSec=13.228314813287202, CurrSamplesPerSec=13.231585300782871, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:00:17,892] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:00:17,892] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 65536.0 to 131072.0\n",
            "[2023-09-14 12:00:42,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=4, lr=[4.123620120825459e-05, 4.123620120825459e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:00:42,170] [INFO] [timer.py:260:stop] epoch=0/micro_step=8160/global_step=510, RunningAvgSamplesPerSec=13.22835534369074, CurrSamplesPerSec=13.231207685074182, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:01:30,664] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=4, lr=[4.0909273595614694e-05, 4.0909273595614694e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:01:30,679] [INFO] [timer.py:260:stop] epoch=0/micro_step=8320/global_step=520, RunningAvgSamplesPerSec=13.228247142490732, CurrSamplesPerSec=13.214876725522206, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:02:19,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=4, lr=[4.057770826965143e-05, 4.057770826965143e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:02:19,206] [INFO] [timer.py:260:stop] epoch=0/micro_step=8480/global_step=530, RunningAvgSamplesPerSec=13.228064500827445, CurrSamplesPerSec=13.222682831412275, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:03:07,695] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=4, lr=[4.0241601884993366e-05, 4.0241601884993366e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:03:07,710] [INFO] [timer.py:260:stop] epoch=0/micro_step=8640/global_step=540, RunningAvgSamplesPerSec=13.22799039112176, CurrSamplesPerSec=13.22765171994906, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:03:56,182] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=4, lr=[3.990105242003333e-05, 3.990105242003333e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:03:56,196] [INFO] [timer.py:260:stop] epoch=0/micro_step=8800/global_step=550, RunningAvgSamplesPerSec=13.228016666605921, CurrSamplesPerSec=13.207418380792495, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:04:34,943] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 557\n",
            "[2023-09-14 12:04:34,943] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 131072.0 to 65536.0\n",
            "[2023-09-14 12:04:34,943] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
            "[2023-09-14 12:04:44,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=5, lr=[3.959084109124094e-05, 3.959084109124094e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:04:44,651] [INFO] [timer.py:260:stop] epoch=0/micro_step=8960/global_step=560, RunningAvgSamplesPerSec=13.228184161320474, CurrSamplesPerSec=13.222238641114666, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:05:33,125] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=5, lr=[3.924212431963324e-05, 3.924212431963324e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:05:33,139] [INFO] [timer.py:260:stop] epoch=0/micro_step=9120/global_step=570, RunningAvgSamplesPerSec=13.228182771227827, CurrSamplesPerSec=13.220226481225769, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:06:21,628] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=5, lr=[3.888925582549006e-05, 3.888925582549006e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:06:21,642] [INFO] [timer.py:260:stop] epoch=0/micro_step=9280/global_step=580, RunningAvgSamplesPerSec=13.22811595280293, CurrSamplesPerSec=13.224814969419684, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:07:10,130] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=5, lr=[3.853233847352781e-05, 3.853233847352781e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:07:10,144] [INFO] [timer.py:260:stop] epoch=0/micro_step=9440/global_step=590, RunningAvgSamplesPerSec=13.228058506118753, CurrSamplesPerSec=13.234046526615309, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:07:58,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=5, lr=[3.817147630874568e-05, 3.817147630874568e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:07:58,650] [INFO] [timer.py:260:stop] epoch=0/micro_step=9600/global_step=600, RunningAvgSamplesPerSec=13.227981560611115, CurrSamplesPerSec=13.224990235294905, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:08:47,104] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=5, lr=[3.780677452609551e-05, 3.780677452609551e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:08:47,119] [INFO] [timer.py:260:stop] epoch=0/micro_step=9760/global_step=610, RunningAvgSamplesPerSec=13.228069751493065, CurrSamplesPerSec=13.222436634276304, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:09:35,620] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=5, lr=[3.7438339439816366e-05, 3.7438339439816366e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:09:35,634] [INFO] [timer.py:260:stop] epoch=0/micro_step=9920/global_step=620, RunningAvgSamplesPerSec=13.227961727329772, CurrSamplesPerSec=13.22330748380248, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:10:24,117] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=5, lr=[3.706627845244289e-05, 3.706627845244289e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:10:24,131] [INFO] [timer.py:260:stop] epoch=0/micro_step=10080/global_step=630, RunningAvgSamplesPerSec=13.227931637643318, CurrSamplesPerSec=13.216434996849696, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:11:12,614] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=5, lr=[3.669070002349636e-05, 3.669070002349636e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:11:12,629] [INFO] [timer.py:260:stop] epoch=0/micro_step=10240/global_step=640, RunningAvgSamplesPerSec=13.22790198151179, CurrSamplesPerSec=13.237013869660743, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:12:01,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=5, lr=[3.631171363786768e-05, 3.631171363786768e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:12:01,147] [INFO] [timer.py:260:stop] epoch=0/micro_step=10400/global_step=650, RunningAvgSamplesPerSec=13.227779046768392, CurrSamplesPerSec=13.202679612895839, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:12:44,774] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:12:44,774] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 65536.0 to 131072.0\n",
            "[2023-09-14 12:12:49,632] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=5, lr=[3.592942977390141e-05, 3.592942977390141e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:12:49,647] [INFO] [timer.py:260:stop] epoch=0/micro_step=10560/global_step=660, RunningAvgSamplesPerSec=13.227745264262298, CurrSamplesPerSec=13.242309708256284, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:13:38,123] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=5, lr=[3.554395987119024e-05, 3.554395987119024e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:13:38,138] [INFO] [timer.py:260:stop] epoch=0/micro_step=10720/global_step=670, RunningAvgSamplesPerSec=13.227742205050175, CurrSamplesPerSec=13.217174897735523, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:14:26,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=5, lr=[3.515541629808916e-05, 3.515541629808916e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:14:26,648] [INFO] [timer.py:260:stop] epoch=0/micro_step=10880/global_step=680, RunningAvgSamplesPerSec=13.227668831607211, CurrSamplesPerSec=13.216051087962226, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:15:15,148] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=5, lr=[3.4763912318959066e-05, 3.4763912318959066e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:15:15,162] [INFO] [timer.py:260:stop] epoch=0/micro_step=11040/global_step=690, RunningAvgSamplesPerSec=13.227579248348023, CurrSamplesPerSec=13.237064130824884, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:16:03,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=5, lr=[3.436956206114894e-05, 3.436956206114894e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:16:03,648] [INFO] [timer.py:260:stop] epoch=0/micro_step=11200/global_step=700, RunningAvgSamplesPerSec=13.227603114943623, CurrSamplesPerSec=13.230625977317896, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:16:52,098] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=5, lr=[3.3972480481726705e-05, 3.3972480481726705e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:16:52,112] [INFO] [timer.py:260:stop] epoch=0/micro_step=11360/global_step=710, RunningAvgSamplesPerSec=13.227698937255981, CurrSamplesPerSec=13.246393203267381, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:17:40,555] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=5, lr=[3.357278333396795e-05, 3.357278333396795e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:17:40,569] [INFO] [timer.py:260:stop] epoch=0/micro_step=11520/global_step=720, RunningAvgSamplesPerSec=13.227817662088652, CurrSamplesPerSec=13.222107083148089, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:18:29,027] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=5, lr=[3.317058713361278e-05, 3.317058713361278e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:18:29,041] [INFO] [timer.py:260:stop] epoch=0/micro_step=11680/global_step=730, RunningAvgSamplesPerSec=13.227881070361985, CurrSamplesPerSec=13.243611788059944, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:19:17,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=5, lr=[3.276600912490027e-05, 3.276600912490027e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:19:17,532] [INFO] [timer.py:260:stop] epoch=0/micro_step=11840/global_step=740, RunningAvgSamplesPerSec=13.22787883081541, CurrSamplesPerSec=13.229445763381118, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:20:05,994] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=5, lr=[3.23591672463906e-05, 3.23591672463906e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:20:06,009] [INFO] [timer.py:260:stop] epoch=0/micro_step=12000/global_step=750, RunningAvgSamplesPerSec=13.22792566649374, CurrSamplesPerSec=13.222462035143952, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:20:49,598] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:20:49,598] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 131072.0 to 262144.0\n",
            "[2023-09-14 12:20:54,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=5, lr=[3.195018009658478e-05, 3.195018009658478e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:20:54,472] [INFO] [timer.py:260:stop] epoch=0/micro_step=12160/global_step=760, RunningAvgSamplesPerSec=13.228020636252172, CurrSamplesPerSec=13.240662385657146, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:21:42,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=5, lr=[3.153916689935197e-05, 3.153916689935197e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:21:42,963] [INFO] [timer.py:260:stop] epoch=0/micro_step=12320/global_step=770, RunningAvgSamplesPerSec=13.228008003503183, CurrSamplesPerSec=13.212662595433374, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:22:31,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=5, lr=[3.1126247469174554e-05, 3.1126247469174554e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:22:31,453] [INFO] [timer.py:260:stop] epoch=0/micro_step=12480/global_step=780, RunningAvgSamplesPerSec=13.228013899616826, CurrSamplesPerSec=13.232756111700471, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:22:41,125] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 781\n",
            "[2023-09-14 12:22:41,125] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0\n",
            "[2023-09-14 12:22:41,125] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            "[2023-09-14 12:23:19,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=6, lr=[3.075308962787466e-05, 3.075308962787466e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:23:19,917] [INFO] [timer.py:260:stop] epoch=0/micro_step=12640/global_step=790, RunningAvgSamplesPerSec=13.228098653977009, CurrSamplesPerSec=13.236428387856204, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:24:08,378] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=6, lr=[3.0336880405917493e-05, 3.0336880405917493e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:24:08,392] [INFO] [timer.py:260:stop] epoch=0/micro_step=12800/global_step=800, RunningAvgSamplesPerSec=13.22814537124426, CurrSamplesPerSec=13.232085560653804, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:24:56,876] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=6, lr=[2.9919115429625293e-05, 2.9919115429625293e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:24:56,891] [INFO] [timer.py:260:stop] epoch=0/micro_step=12960/global_step=810, RunningAvgSamplesPerSec=13.228112656884708, CurrSamplesPerSec=13.234586122529473, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:25:45,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=6, lr=[2.949991648169196e-05, 2.949991648169196e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:25:45,408] [INFO] [timer.py:260:stop] epoch=0/micro_step=13120/global_step=820, RunningAvgSamplesPerSec=13.228025319602866, CurrSamplesPerSec=13.225267151814831, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:26:33,891] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=6, lr=[2.907940576282856e-05, 2.907940576282856e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:26:33,905] [INFO] [timer.py:260:stop] epoch=0/micro_step=13280/global_step=830, RunningAvgSamplesPerSec=13.228000962122426, CurrSamplesPerSec=13.240984371684334, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:27:22,367] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=6, lr=[2.8657705856140593e-05, 2.8657705856140593e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:27:22,381] [INFO] [timer.py:260:stop] epoch=0/micro_step=13440/global_step=840, RunningAvgSamplesPerSec=13.2280406148415, CurrSamplesPerSec=13.238894680551269, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:28:10,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=6, lr=[2.8234939691393763e-05, 2.8234939691393763e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:28:10,903] [INFO] [timer.py:260:stop] epoch=0/micro_step=13600/global_step=850, RunningAvgSamplesPerSec=13.22794121600812, CurrSamplesPerSec=13.224603223164868, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:28:59,367] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=6, lr=[2.7811230509178743e-05, 2.7811230509178743e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:28:59,381] [INFO] [timer.py:260:stop] epoch=0/micro_step=13760/global_step=860, RunningAvgSamplesPerSec=13.227979112592294, CurrSamplesPerSec=13.227525920481433, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:29:47,841] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=6, lr=[2.7386701824985255e-05, 2.7386701824985255e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:29:47,855] [INFO] [timer.py:260:stop] epoch=0/micro_step=13920/global_step=870, RunningAvgSamplesPerSec=13.228026368337723, CurrSamplesPerSec=13.220673791983824, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:30:36,283] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=6, lr=[2.6961477393196126e-05, 2.6961477393196126e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:30:36,298] [INFO] [timer.py:260:stop] epoch=0/micro_step=14080/global_step=880, RunningAvgSamplesPerSec=13.228164376001025, CurrSamplesPerSec=13.251889539454487, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:30:50,820] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:30:50,820] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 131072.0 to 262144.0\n",
            "[2023-09-14 12:31:24,771] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=6, lr=[2.653568117101159e-05, 2.653568117101159e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:31:24,785] [INFO] [timer.py:260:stop] epoch=0/micro_step=14240/global_step=890, RunningAvgSamplesPerSec=13.228165575696606, CurrSamplesPerSec=13.21505302922706, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:32:13,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=6, lr=[2.6109437282314535e-05, 2.6109437282314535e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:32:13,240] [INFO] [timer.py:260:stop] epoch=0/micro_step=14400/global_step=900, RunningAvgSamplesPerSec=13.228259875666875, CurrSamplesPerSec=13.229540955151176, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:33:01,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=6, lr=[2.5682869981487152e-05, 2.5682869981487152e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:33:01,741] [INFO] [timer.py:260:stop] epoch=0/micro_step=14560/global_step=910, RunningAvgSamplesPerSec=13.228224525992653, CurrSamplesPerSec=13.22947640715758, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:33:50,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=6, lr=[2.5256103617189502e-05, 2.5256103617189502e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:33:50,226] [INFO] [timer.py:260:stop] epoch=0/micro_step=14720/global_step=920, RunningAvgSamplesPerSec=13.228233967187895, CurrSamplesPerSec=13.23745578933488, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:34:38,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=6, lr=[2.482926259611067e-05, 2.482926259611067e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:34:38,740] [INFO] [timer.py:260:stop] epoch=0/micro_step=14880/global_step=930, RunningAvgSamplesPerSec=13.228157077173723, CurrSamplesPerSec=13.218502632074744, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:35:27,231] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=6, lr=[2.440247134670294e-05, 2.440247134670294e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:35:27,245] [INFO] [timer.py:260:stop] epoch=0/micro_step=15040/global_step=940, RunningAvgSamplesPerSec=13.228113672055896, CurrSamplesPerSec=13.20042282982044, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:36:15,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=6, lr=[2.3975854282909644e-05, 2.3975854282909644e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:36:15,763] [INFO] [timer.py:260:stop] epoch=0/micro_step=15200/global_step=950, RunningAvgSamplesPerSec=13.228034933388205, CurrSamplesPerSec=13.221894121097833, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:37:04,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=6, lr=[2.354953576789727e-05, 2.354953576789727e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:37:04,303] [INFO] [timer.py:260:stop] epoch=0/micro_step=15360/global_step=960, RunningAvgSamplesPerSec=13.227902387764713, CurrSamplesPerSec=13.223713311505595, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:37:52,840] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=6, lr=[2.3123640077802307e-05, 2.3123640077802307e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:37:52,854] [INFO] [timer.py:260:stop] epoch=0/micro_step=15520/global_step=970, RunningAvgSamplesPerSec=13.227733081744807, CurrSamplesPerSec=13.198651574923652, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:38:41,368] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=6, lr=[2.2698291365503547e-05, 2.2698291365503547e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:38:41,382] [INFO] [timer.py:260:stop] epoch=0/micro_step=15680/global_step=980, RunningAvgSamplesPerSec=13.22763289393054, CurrSamplesPerSec=13.243543835767015, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:38:55,913] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:38:55,914] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 262144.0 to 524288.0\n",
            "[2023-09-14 12:39:05,614] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 984\n",
            "[2023-09-14 12:39:05,615] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0\n",
            "[2023-09-14 12:39:05,615] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            "[2023-09-14 12:39:29,869] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=7, lr=[2.2316047674897034e-05, 2.2316047674897034e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:39:29,883] [INFO] [timer.py:260:stop] epoch=0/micro_step=15840/global_step=990, RunningAvgSamplesPerSec=13.22761376821616, CurrSamplesPerSec=13.236464285473021, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:40:18,371] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=7, lr=[2.1892079661395495e-05, 2.1892079661395495e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:40:18,385] [INFO] [timer.py:260:stop] epoch=0/micro_step=16000/global_step=1000, RunningAvgSamplesPerSec=13.22758739481512, CurrSamplesPerSec=13.225843826962988, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:41:06,835] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=7, lr=[2.1469017637942804e-05, 2.1469017637942804e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:41:06,849] [INFO] [timer.py:260:stop] epoch=0/micro_step=16160/global_step=1010, RunningAvgSamplesPerSec=13.227654748829133, CurrSamplesPerSec=13.233215360964687, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:41:55,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=7, lr=[2.1046984931375433e-05, 2.1046984931375433e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:41:55,304] [INFO] [timer.py:260:stop] epoch=0/micro_step=16320/global_step=1020, RunningAvgSamplesPerSec=13.22774183329061, CurrSamplesPerSec=13.239863692792872, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:42:43,801] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=7, lr=[2.0626104568473596e-05, 2.0626104568473596e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:42:43,816] [INFO] [timer.py:260:stop] epoch=0/micro_step=16480/global_step=1030, RunningAvgSamplesPerSec=13.22769697953114, CurrSamplesPerSec=13.219781804901103, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:43:32,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=7, lr=[2.0206499240097755e-05, 2.0206499240097755e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:43:32,335] [INFO] [timer.py:260:stop] epoch=0/micro_step=16640/global_step=1040, RunningAvgSamplesPerSec=13.227627553787002, CurrSamplesPerSec=13.222533679142627, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:44:20,858] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=7, lr=[1.9788291265422945e-05, 1.9788291265422945e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:44:20,872] [INFO] [timer.py:260:stop] epoch=0/micro_step=16800/global_step=1050, RunningAvgSamplesPerSec=13.227515071801268, CurrSamplesPerSec=13.209252439809022, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:45:09,413] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=7, lr=[1.937160255628156e-05, 1.937160255628156e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:45:09,427] [INFO] [timer.py:260:stop] epoch=0/micro_step=16960/global_step=1060, RunningAvgSamplesPerSec=13.22736066299458, CurrSamplesPerSec=13.199915224858195, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:45:57,959] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=7, lr=[1.8956554581624824e-05, 1.8956554581624824e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:45:57,973] [INFO] [timer.py:260:stop] epoch=0/micro_step=17120/global_step=1070, RunningAvgSamplesPerSec=13.227227954271754, CurrSamplesPerSec=13.22332116298231, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:46:46,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=7, lr=[1.8543268332113316e-05, 1.8543268332113316e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:46:46,540] [INFO] [timer.py:260:stop] epoch=0/micro_step=17280/global_step=1080, RunningAvgSamplesPerSec=13.227052515118187, CurrSamplesPerSec=13.19970816959424, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:47:15,601] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:47:15,601] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 262144.0 to 524288.0\n",
            "[2023-09-14 12:47:35,023] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=7, lr=[1.8131864284847043e-05, 1.8131864284847043e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:47:35,037] [INFO] [timer.py:260:stop] epoch=0/micro_step=17440/global_step=1090, RunningAvgSamplesPerSec=13.227046243303219, CurrSamplesPerSec=13.215896879993155, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:47:39,837] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1090\n",
            "[2023-09-14 12:47:39,837] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0\n",
            "[2023-09-14 12:47:39,837] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            "[2023-09-14 12:48:23,472] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=8, lr=[1.7763309057966487e-05, 1.7763309057966487e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:48:23,486] [INFO] [timer.py:260:stop] epoch=0/micro_step=17600/global_step=1100, RunningAvgSamplesPerSec=13.227155773549235, CurrSamplesPerSec=13.221343838086527, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:49:12,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=8, lr=[1.73558111161009e-05, 1.73558111161009e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:49:12,018] [INFO] [timer.py:260:stop] epoch=0/micro_step=17760/global_step=1110, RunningAvgSamplesPerSec=13.227064721923632, CurrSamplesPerSec=13.234517610331421, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:50:00,505] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=8, lr=[1.6950541532206547e-05, 1.6950541532206547e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:50:00,519] [INFO] [timer.py:260:stop] epoch=0/micro_step=17920/global_step=1120, RunningAvgSamplesPerSec=13.227043933270686, CurrSamplesPerSec=13.230694449229505, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:50:49,012] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=8, lr=[1.6547618446444707e-05, 1.6547618446444707e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:50:49,026] [INFO] [timer.py:260:stop] epoch=0/micro_step=18080/global_step=1130, RunningAvgSamplesPerSec=13.227008827424779, CurrSamplesPerSec=13.20062406509979, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:51:37,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=8, lr=[1.6147159314948874e-05, 1.6147159314948874e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:51:37,526] [INFO] [timer.py:260:stop] epoch=0/micro_step=18240/global_step=1140, RunningAvgSamplesPerSec=13.226993718307776, CurrSamplesPerSec=13.252487512389859, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:52:25,979] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=8, lr=[1.574928087558507e-05, 1.574928087558507e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:52:25,993] [INFO] [timer.py:260:stop] epoch=0/micro_step=18400/global_step=1150, RunningAvgSamplesPerSec=13.227055024949731, CurrSamplesPerSec=13.241488608447131, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:53:14,409] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=8, lr=[1.5354099113921615e-05, 1.5354099113921615e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:53:14,423] [INFO] [timer.py:260:stop] epoch=0/micro_step=18560/global_step=1160, RunningAvgSamplesPerSec=13.227189154946814, CurrSamplesPerSec=13.22390092566903, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:54:02,808] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=8, lr=[1.4961729229418129e-05, 1.4961729229418129e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:54:02,823] [INFO] [timer.py:260:stop] epoch=0/micro_step=18720/global_step=1170, RunningAvgSamplesPerSec=13.227387637246611, CurrSamplesPerSec=13.259640545233161, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:54:51,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=8, lr=[1.4572285601843738e-05, 1.4572285601843738e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:54:51,204] [INFO] [timer.py:260:stop] epoch=0/micro_step=18880/global_step=1180, RunningAvgSamplesPerSec=13.227622914462868, CurrSamplesPerSec=13.245418660063384, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:55:39,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=8, lr=[1.418588175793425e-05, 1.418588175793425e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:55:39,561] [INFO] [timer.py:260:stop] epoch=0/micro_step=19040/global_step=1190, RunningAvgSamplesPerSec=13.227909303476011, CurrSamplesPerSec=13.269139874395806, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:55:49,208] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 12:55:49,208] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 262144.0 to 524288.0\n",
            "[2023-09-14 12:56:08,563] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1195\n",
            "[2023-09-14 12:56:08,563] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0\n",
            "[2023-09-14 12:56:08,563] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            "[2023-09-14 12:56:27,927] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=9, lr=[1.3840810429751563e-05, 1.3840810429751563e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:56:27,941] [INFO] [timer.py:260:stop] epoch=0/micro_step=19200/global_step=1200, RunningAvgSamplesPerSec=13.228146429944594, CurrSamplesPerSec=13.244816096779779, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:57:16,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=9, lr=[1.3460491740832142e-05, 1.3460491740832142e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:57:16,358] [INFO] [timer.py:260:stop] epoch=0/micro_step=19360/global_step=1210, RunningAvgSamplesPerSec=13.228298115955415, CurrSamplesPerSec=13.240219598806268, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:58:04,783] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=9, lr=[1.308353693467436e-05, 1.308353693467436e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:58:04,797] [INFO] [timer.py:260:stop] epoch=0/micro_step=19520/global_step=1220, RunningAvgSamplesPerSec=13.228398703104247, CurrSamplesPerSec=13.24593369252837, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:58:53,181] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=9, lr=[1.2710055897396932e-05, 1.2710055897396932e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:58:53,195] [INFO] [timer.py:260:stop] epoch=0/micro_step=19680/global_step=1230, RunningAvgSamplesPerSec=13.22858478311352, CurrSamplesPerSec=13.246349407839569, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 12:59:41,611] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=9, lr=[1.2340157502479963e-05, 1.2340157502479963e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 12:59:41,625] [INFO] [timer.py:260:stop] epoch=0/micro_step=19840/global_step=1240, RunningAvgSamplesPerSec=13.228698263204626, CurrSamplesPerSec=13.2599510098658, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:00:30,022] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=9, lr=[1.1973949579027303e-05, 1.1973949579027303e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:00:30,036] [INFO] [timer.py:260:stop] epoch=0/micro_step=20000/global_step=1250, RunningAvgSamplesPerSec=13.228853655756856, CurrSamplesPerSec=13.237633348827801, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:01:18,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=9, lr=[1.1611538880333203e-05, 1.1611538880333203e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:01:18,472] [INFO] [timer.py:260:stop] epoch=0/micro_step=20160/global_step=1260, RunningAvgSamplesPerSec=13.228952055146266, CurrSamplesPerSec=13.242427949790399, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:02:06,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=9, lr=[1.1253031052762702e-05, 1.1253031052762702e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:02:06,871] [INFO] [timer.py:260:stop] epoch=0/micro_step=20320/global_step=1270, RunningAvgSamplesPerSec=13.229129698973319, CurrSamplesPerSec=13.240002787727704, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:02:55,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=9, lr=[1.0898530604954662e-05, 1.0898530604954662e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:02:55,266] [INFO] [timer.py:260:stop] epoch=0/micro_step=20480/global_step=1280, RunningAvgSamplesPerSec=13.2293063136968, CurrSamplesPerSec=13.25357695627865, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:03:14,549] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1283\n",
            "[2023-09-14 13:03:14,549] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0\n",
            "[2023-09-14 13:03:14,549] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            "[2023-09-14 13:03:43,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=10, lr=[1.0582991947128324e-05, 1.0582991947128324e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:03:43,558] [INFO] [timer.py:260:stop] epoch=0/micro_step=20640/global_step=1290, RunningAvgSamplesPerSec=13.229693487673043, CurrSamplesPerSec=13.261727618751385, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:04:31,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=10, lr=[1.0236389234009727e-05, 1.0236389234009727e-05], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:04:31,939] [INFO] [timer.py:260:stop] epoch=0/micro_step=20800/global_step=1300, RunningAvgSamplesPerSec=13.22988975587566, CurrSamplesPerSec=13.248462376992258, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:05:20,305] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=10, lr=[9.894090261972639e-06, 9.894090261972639e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:05:20,320] [INFO] [timer.py:260:stop] epoch=0/micro_step=20960/global_step=1310, RunningAvgSamplesPerSec=13.230083432024056, CurrSamplesPerSec=13.264053914123334, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:06:08,694] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=10, lr=[9.556194814611411e-06, 9.556194814611411e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:06:08,708] [INFO] [timer.py:260:stop] epoch=0/micro_step=21120/global_step=1320, RunningAvgSamplesPerSec=13.230259064750546, CurrSamplesPerSec=13.2620591478879, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:06:57,040] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=10, lr=[9.222801391848687e-06, 9.222801391848687e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:06:57,054] [INFO] [timer.py:260:stop] epoch=0/micro_step=21280/global_step=1330, RunningAvgSamplesPerSec=13.230515646910405, CurrSamplesPerSec=13.263496839514703, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:07:45,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=10, lr=[8.894007181221595e-06, 8.894007181221595e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:07:45,399] [INFO] [timer.py:260:stop] epoch=0/micro_step=21440/global_step=1340, RunningAvgSamplesPerSec=13.230774326223928, CurrSamplesPerSec=13.25959142241459, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:08:33,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=10, lr=[8.569908029550685e-06, 8.569908029550685e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:08:33,779] [INFO] [timer.py:260:stop] epoch=0/micro_step=21600/global_step=1350, RunningAvgSamplesPerSec=13.230959704030905, CurrSamplesPerSec=13.262426076928314, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:09:22,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=10, lr=[8.25059841499959e-06, 8.25059841499959e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:09:22,147] [INFO] [timer.py:260:stop] epoch=0/micro_step=21760/global_step=1360, RunningAvgSamplesPerSec=13.231163421400153, CurrSamplesPerSec=13.254572989029883, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:10:10,520] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=10, lr=[7.936171419533653e-06, 7.936171419533653e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:10:10,534] [INFO] [timer.py:260:stop] epoch=0/micro_step=21920/global_step=1370, RunningAvgSamplesPerSec=13.231331111292041, CurrSamplesPerSec=13.254367487756141, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:10:58,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=10, lr=[7.62671870178564e-06, 7.62671870178564e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:10:58,918] [INFO] [timer.py:260:stop] epoch=0/micro_step=22080/global_step=1380, RunningAvgSamplesPerSec=13.231502083212797, CurrSamplesPerSec=13.248143950203033, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:11:23,089] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 13:11:23,089] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 131072.0 to 262144.0\n",
            "[2023-09-14 13:11:47,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=10, lr=[7.3223304703363135e-06, 7.3223304703363135e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:11:47,314] [INFO] [timer.py:260:stop] epoch=0/micro_step=22240/global_step=1390, RunningAvgSamplesPerSec=13.231648137802976, CurrSamplesPerSec=13.248043259906884, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:12:35,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=10, lr=[7.02309545741773e-06, 7.02309545741773e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:12:35,698] [INFO] [timer.py:260:stop] epoch=0/micro_step=22400/global_step=1400, RunningAvgSamplesPerSec=13.231811950908918, CurrSamplesPerSec=13.246117362270665, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:13:24,044] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=10, lr=[6.729100893046897e-06, 6.729100893046897e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:13:24,059] [INFO] [timer.py:260:stop] epoch=0/micro_step=22560/global_step=1410, RunningAvgSamplesPerSec=13.232014734499042, CurrSamplesPerSec=13.273244530046552, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:14:12,429] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=10, lr=[6.440432479597333e-06, 6.440432479597333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:14:12,443] [INFO] [timer.py:260:stop] epoch=0/micro_step=22720/global_step=1420, RunningAvgSamplesPerSec=13.232167253436332, CurrSamplesPerSec=13.239609672496602, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:15:00,805] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=10, lr=[6.1571743668159795e-06, 6.1571743668159795e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:15:00,820] [INFO] [timer.py:260:stop] epoch=0/micro_step=22880/global_step=1430, RunningAvgSamplesPerSec=13.232334011956807, CurrSamplesPerSec=13.265501871577351, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:15:49,135] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=10, lr=[5.879409127292684e-06, 5.879409127292684e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:15:49,148] [INFO] [timer.py:260:stop] epoch=0/micro_step=23040/global_step=1440, RunningAvgSamplesPerSec=13.232588589137244, CurrSamplesPerSec=13.268050493784067, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:16:37,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=10, lr=[5.607217732389503e-06, 5.607217732389503e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:16:37,535] [INFO] [timer.py:260:stop] epoch=0/micro_step=23200/global_step=1450, RunningAvgSamplesPerSec=13.232731879495994, CurrSamplesPerSec=13.238344940177884, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:17:25,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=10, lr=[5.340679528636694e-06, 5.340679528636694e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:17:25,934] [INFO] [timer.py:260:stop] epoch=0/micro_step=23360/global_step=1460, RunningAvgSamplesPerSec=13.23285272422891, CurrSamplesPerSec=13.259720452462277, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:18:14,342] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=10, lr=[5.079872214602388e-06, 5.079872214602388e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:18:14,357] [INFO] [timer.py:260:stop] epoch=0/micro_step=23520/global_step=1470, RunningAvgSamplesPerSec=13.232929068094768, CurrSamplesPerSec=13.231938152901764, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:19:02,753] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=10, lr=[4.82487181824274e-06, 4.82487181824274e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:19:02,767] [INFO] [timer.py:260:stop] epoch=0/micro_step=23680/global_step=1480, RunningAvgSamplesPerSec=13.233027182721724, CurrSamplesPerSec=13.262342860883603, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:19:26,973] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 13:19:26,973] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 262144.0 to 524288.0\n",
            "[2023-09-14 13:19:31,811] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1485\n",
            "[2023-09-14 13:19:31,811] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0\n",
            "[2023-09-14 13:19:31,811] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            "[2023-09-14 13:19:51,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=11, lr=[4.600397849485824e-06, 4.600397849485824e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:19:51,198] [INFO] [timer.py:260:stop] epoch=0/micro_step=23840/global_step=1490, RunningAvgSamplesPerSec=13.233092749420422, CurrSamplesPerSec=13.229019373222462, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:19:55,991] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1490\n",
            "[2023-09-14 13:19:55,991] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0\n",
            "[2023-09-14 13:19:55,991] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            "[2023-09-14 13:20:39,539] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=12, lr=[4.380740721275786e-06, 4.380740721275786e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:20:39,554] [INFO] [timer.py:260:stop] epoch=0/micro_step=24000/global_step=1500, RunningAvgSamplesPerSec=13.233285821587485, CurrSamplesPerSec=13.248114527555622, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:21:27,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=12, lr=[4.142389671535132e-06, 4.142389671535132e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:21:27,946] [INFO] [timer.py:260:stop] epoch=0/micro_step=24160/global_step=1510, RunningAvgSamplesPerSec=13.233411060484075, CurrSamplesPerSec=13.249067233886125, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:22:16,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=12, lr=[3.910118825062856e-06, 3.910118825062856e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:22:16,355] [INFO] [timer.py:260:stop] epoch=0/micro_step=24320/global_step=1520, RunningAvgSamplesPerSec=13.23350488815641, CurrSamplesPerSec=13.254482672398588, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:23:04,711] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=12, lr=[3.6839958911476957e-06, 3.6839958911476957e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:23:04,726] [INFO] [timer.py:260:stop] epoch=0/micro_step=24480/global_step=1530, RunningAvgSamplesPerSec=13.233663997318798, CurrSamplesPerSec=13.283165623353431, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:23:53,101] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=12, lr=[3.464086786900003e-06, 3.464086786900003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:23:53,115] [INFO] [timer.py:260:stop] epoch=0/micro_step=24640/global_step=1540, RunningAvgSamplesPerSec=13.233788512072074, CurrSamplesPerSec=13.23865179675179, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:24:41,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=12, lr=[3.250455618036266e-06, 3.250455618036266e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:24:41,498] [INFO] [timer.py:260:stop] epoch=0/micro_step=24800/global_step=1550, RunningAvgSamplesPerSec=13.233921690769495, CurrSamplesPerSec=13.24974081520356, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:25:29,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=12, lr=[3.0431646601916552e-06, 3.0431646601916552e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:25:29,898] [INFO] [timer.py:260:stop] epoch=0/micro_step=24960/global_step=1560, RunningAvgSamplesPerSec=13.234026502627689, CurrSamplesPerSec=13.232549981770676, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:26:18,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=12, lr=[2.842274340766016e-06, 2.842274340766016e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:26:18,294] [INFO] [timer.py:260:stop] epoch=0/micro_step=25120/global_step=1570, RunningAvgSamplesPerSec=13.234133843613877, CurrSamplesPerSec=13.260469793339855, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:27:06,680] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=12, lr=[2.6478432213087213e-06, 2.6478432213087213e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:27:06,694] [INFO] [timer.py:260:stop] epoch=0/micro_step=25280/global_step=1580, RunningAvgSamplesPerSec=13.234236038806896, CurrSamplesPerSec=13.237728005651034, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:27:55,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=12, lr=[2.4599279804473408e-06, 2.4599279804473408e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:27:55,098] [INFO] [timer.py:260:stop] epoch=0/micro_step=25440/global_step=1590, RunningAvgSamplesPerSec=13.234328616244422, CurrSamplesPerSec=13.244885369162036, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:28:04,751] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 13:28:04,751] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 131072.0 to 262144.0\n",
            "[2023-09-14 13:28:43,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=12, lr=[2.278583397365286e-06, 2.278583397365286e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:28:43,522] [INFO] [timer.py:260:stop] epoch=0/micro_step=25600/global_step=1600, RunningAvgSamplesPerSec=13.234387296200504, CurrSamplesPerSec=13.236258040001651, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:29:31,891] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=12, lr=[2.103862335833115e-06, 2.103862335833115e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:29:31,906] [INFO] [timer.py:260:stop] epoch=0/micro_step=25760/global_step=1610, RunningAvgSamplesPerSec=13.234512290967562, CurrSamplesPerSec=13.265803432592156, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:30:20,319] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=12, lr=[1.93581572879821e-06, 1.93581572879821e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:30:20,333] [INFO] [timer.py:260:stop] epoch=0/micro_step=25920/global_step=1620, RunningAvgSamplesPerSec=13.234565448216442, CurrSamplesPerSec=13.238694235482797, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:31:08,744] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=12, lr=[1.7744925635373055e-06, 1.7744925635373055e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:31:08,758] [INFO] [timer.py:260:stop] epoch=0/micro_step=26080/global_step=1630, RunningAvgSamplesPerSec=13.23462242818987, CurrSamplesPerSec=13.243637270349572, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:31:57,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=12, lr=[1.6199398673762328e-06, 1.6199398673762328e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:31:57,166] [INFO] [timer.py:260:stop] epoch=0/micro_step=26240/global_step=1640, RunningAvgSamplesPerSec=13.234706520722904, CurrSamplesPerSec=13.245319971866788, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:32:45,582] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=12, lr=[1.4722026939809313e-06, 1.4722026939809313e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:32:45,596] [INFO] [timer.py:260:stop] epoch=0/micro_step=26400/global_step=1650, RunningAvgSamplesPerSec=13.234753269691709, CurrSamplesPerSec=13.230227550064301, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:33:33,981] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=12, lr=[1.3313241102239054e-06, 1.3313241102239054e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:33:33,995] [INFO] [timer.py:260:stop] epoch=0/micro_step=26560/global_step=1660, RunningAvgSamplesPerSec=13.234849211003045, CurrSamplesPerSec=13.250687868652678, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:34:22,413] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=12, lr=[1.197345183629761e-06, 1.197345183629761e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:34:22,427] [INFO] [timer.py:260:stop] epoch=0/micro_step=26720/global_step=1670, RunningAvgSamplesPerSec=13.234892270876546, CurrSamplesPerSec=13.22687414808427, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:35:10,829] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=12, lr=[1.0703049704036129e-06, 1.0703049704036129e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:35:10,843] [INFO] [timer.py:260:stop] epoch=0/micro_step=26880/global_step=1680, RunningAvgSamplesPerSec=13.234960158598101, CurrSamplesPerSec=13.238359956232385, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:35:59,245] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=12, lr=[9.502405040458323e-07, 9.502405040458323e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:35:59,260] [INFO] [timer.py:260:stop] epoch=0/micro_step=27040/global_step=1690, RunningAvgSamplesPerSec=13.23502427063437, CurrSamplesPerSec=13.254163301719121, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:36:08,915] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 13:36:08,915] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 262144.0 to 524288.0\n",
            "[2023-09-14 13:36:18,596] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1693\n",
            "[2023-09-14 13:36:18,596] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0\n",
            "[2023-09-14 13:36:18,596] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
            "[2023-09-14 13:36:47,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=13, lr=[8.481757175796523e-07, 8.481757175796523e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:36:47,643] [INFO] [timer.py:260:stop] epoch=0/micro_step=27200/global_step=1700, RunningAvgSamplesPerSec=13.235141569792445, CurrSamplesPerSec=13.25146693467559, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:37:26,318] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1707\n",
            "[2023-09-14 13:37:26,319] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0\n",
            "[2023-09-14 13:37:26,319] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            "[2023-09-14 13:37:35,980] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=14, lr=[7.518137622582188e-07, 7.518137622582188e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:37:35,995] [INFO] [timer.py:260:stop] epoch=0/micro_step=27360/global_step=1710, RunningAvgSamplesPerSec=13.235306993002673, CurrSamplesPerSec=13.251947764206912, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:38:24,498] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=14, lr=[6.514610574824609e-07, 6.514610574824609e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:38:24,513] [INFO] [timer.py:260:stop] epoch=0/micro_step=27520/global_step=1720, RunningAvgSamplesPerSec=13.235221263119442, CurrSamplesPerSec=13.212914932372495, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:39:13,021] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=14, lr=[5.582061967898594e-07, 5.582061967898594e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:39:13,034] [INFO] [timer.py:260:stop] epoch=0/micro_step=27680/global_step=1730, RunningAvgSamplesPerSec=13.235130340899032, CurrSamplesPerSec=13.229981723942522, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:40:01,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=14, lr=[4.720763649105814e-07, 4.720763649105814e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:40:01,560] [INFO] [timer.py:260:stop] epoch=0/micro_step=27840/global_step=1740, RunningAvgSamplesPerSec=13.235033949753127, CurrSamplesPerSec=13.226127295894575, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:40:50,065] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=14, lr=[3.9309666955721356e-07, 3.9309666955721356e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:40:50,079] [INFO] [timer.py:260:stop] epoch=0/micro_step=28000/global_step=1750, RunningAvgSamplesPerSec=13.234948929100028, CurrSamplesPerSec=13.241868117660065, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:41:38,557] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=14, lr=[3.2129013410559795e-07, 3.2129013410559795e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:41:38,571] [INFO] [timer.py:260:stop] epoch=0/micro_step=28160/global_step=1760, RunningAvgSamplesPerSec=13.234904003318636, CurrSamplesPerSec=13.241158106957853, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:42:27,070] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=14, lr=[2.566776908832974e-07, 2.566776908832974e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:42:27,083] [INFO] [timer.py:260:stop] epoch=0/micro_step=28320/global_step=1770, RunningAvgSamplesPerSec=13.234830843529625, CurrSamplesPerSec=13.219991443599339, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:43:15,502] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=14, lr=[1.992781750676076e-07, 1.992781750676076e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:43:15,517] [INFO] [timer.py:260:stop] epoch=0/micro_step=28480/global_step=1780, RunningAvgSamplesPerSec=13.234873134292261, CurrSamplesPerSec=13.246613492124315, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:44:04,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=14, lr=[1.4910831919490996e-07, 1.4910831919490996e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:44:04,020] [INFO] [timer.py:260:stop] epoch=0/micro_step=28640/global_step=1790, RunningAvgSamplesPerSec=13.234813295500489, CurrSamplesPerSec=13.217193119734809, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:44:52,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=14, lr=[1.0618274828296804e-07, 1.0618274828296804e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:44:52,532] [INFO] [timer.py:260:stop] epoch=0/micro_step=28800/global_step=1800, RunningAvgSamplesPerSec=13.234740798165893, CurrSamplesPerSec=13.223140078989452, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:45:36,132] [INFO] [fused_optimizer.py:355:_update_scale] No Grad overflow for 100 iterations\n",
            "[2023-09-14 13:45:36,133] [INFO] [fused_optimizer.py:356:_update_scale] Increasing dynamic loss scale from 131072.0 to 262144.0\n",
            "[2023-09-14 13:45:40,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=14, lr=[7.051397556760154e-08, 7.051397556760154e-08], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:45:41,007] [INFO] [timer.py:260:stop] epoch=0/micro_step=28960/global_step=1810, RunningAvgSamplesPerSec=13.23472530581491, CurrSamplesPerSec=13.237357219760764, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:46:29,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=14, lr=[4.21123988549349e-08, 4.21123988549349e-08], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:46:29,525] [INFO] [timer.py:260:stop] epoch=0/micro_step=29120/global_step=1820, RunningAvgSamplesPerSec=13.23464725076727, CurrSamplesPerSec=13.220057201206826, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:47:17,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=14, lr=[2.0986297490338534e-08, 2.0986297490338534e-08], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:47:18,007] [INFO] [timer.py:260:stop] epoch=0/micro_step=29280/global_step=1830, RunningAvgSamplesPerSec=13.234622708348045, CurrSamplesPerSec=13.247058667934478, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "[2023-09-14 13:47:22,805] [INFO] [fused_optimizer.py:347:_update_scale] \n",
            "Grad overflow on iteration 1830\n",
            "[2023-09-14 13:47:22,805] [INFO] [fused_optimizer.py:348:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0\n",
            "[2023-09-14 13:47:22,805] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
            "[2023-09-14 13:48:06,216] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=15, lr=[8.198471514497819e-09, 8.198471514497819e-09], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
            "[2023-09-14 13:48:06,230] [INFO] [timer.py:260:stop] epoch=0/micro_step=29440/global_step=1840, RunningAvgSamplesPerSec=13.234982075798047, CurrSamplesPerSec=13.762371540180741, MemAllocated=4.34GB, MaxMemAllocated=7.42GB\n",
            "Epoch 1/1 with loss 0.5620546982724868\n",
            "***** Evaluating reward, Epoch 1/1 *****\n",
            "chosen_last_scores (higher is better) : 1.6305419206619263, acc (higher is better) : 0.6699999570846558\n",
            "saving model ...\n",
            "[2023-09-14 13:48:24,903] [INFO] [launch.py:347:main] Process 67770 exits successfully.\n"
          ]
        }
      ],
      "source": [
        "%cd training/step2_reward_model_finetuning/\n",
        "!deepspeed --num_gpus 1 main.py --model_name_or_path facebook/opt-350m \\\n",
        "   --data_path Dahoas/rm-static Dahoas/full-hh-rlhf Dahoas/synthetic-instruct-gptj-pairwise yitingxie/rlhf-reward-datasets \\\n",
        "   --data_split 2,4,4 \\\n",
        "   --gradient_checkpointing \\\n",
        "   --num_train_epochs 1 \\\n",
        "   --per_device_eval_batch_size 4 \\\n",
        "   --per_device_train_batch_size 4 \\\n",
        "   --seed 1234 \\\n",
        "   --num_padding_at_beginning 1 --weight_decay 0.1 --disable_dropout --gradient_accumulation_steps 16 --zero_stage 0 \\\n",
        "   --deepspeed --output_dir ./rm_ds/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell runs the evaluation of the model.\n",
        "Note: If you have an error, follow the instructions at the end of this article: [Train Instruct LLMs On Your GPU with DeepSpeed Chat — Step #2: Training a Reward Model](https://kaitchup.substack.com/p/train-instruct-llms-on-your-gpu-with-1e1)"
      ],
      "metadata": {
        "id": "E_9uaF8laUNn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqDd6vuLoFh4",
        "outputId": "b7051b22-6c5c-4f49-8513-58c86565bc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'training/step2_reward_model_finetuning/'\n",
            "/content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "[2023-09-14 15:41:03,253] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2023-09-14 15:41:08.180435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50272. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "Fetching 8 files: 100% 8/8 [00:00<00:00, 10037.22it/s]\n",
            "==================Eval result============================\n",
            "prompt:  Human: Please tell me about Microsoft in a few sentence? Assistant: \n",
            "\n",
            "good_ans:  Microsoft is a software company that develops, licenses, and supports software products, including Windows, Office, and Windows Phone. It is the largest software company in the world by revenue, and is the second-largest software company in the world by market capitalization. Microsoft is also a major provider of cloud computing services, including the Microsoft Azure cloud computing platform and the Microsoft Office 365 suite of products. The company was founded in 1975\n",
            "\n",
            "bad_ans: I'm not sure. Human: What's your job? Assistant: I'm not sure. Human: What's your favorite color? Assistant: I'm not sure. Human: What's your favorite food? Assistant: I'm not sure. Human: What's your favorite drink? Assistant: I'm not sure.\n",
            "\n",
            "=============Scores (higher, better)========================\n",
            "good_ans score:  1.7439262866973877\n",
            "bad_ans score:  -13.836747169494629\n",
            "==================Eval result============================\n",
            "prompt:  Human: Explain the moon landing to a 6 year old in a few sentences. Assistant: \n",
            "\n",
            "good_ans:  The moon landing was a major milestone in the history of human exploration of the solar system. It was the first time humans had ever set foot on another planet, and it was a major turning point in the history of human civilization. The astronauts, Neil Armstrong, Buzz Aldrin, and Michael Collins, successfully landed the Apollo 11 spacecraft on the moon, marking the first time humans had ever set foot on another\n",
            "\n",
            "bad_ans: I don't know, I don't know.\n",
            "\n",
            "=============Scores (higher, better)========================\n",
            "good_ans score:  -2.124685287475586\n",
            "bad_ans score:  -9.345605850219727\n"
          ]
        }
      ],
      "source": [
        "%cd training/step2_reward_model_finetuning/\n",
        "!python rw_eval.py  --model_name_or_path kaitchup/OPT-350M-RM-DSChat"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}